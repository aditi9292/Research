\section{Related Work}~\label{sec:related}
In this section, we present the related work in grouping and diagnosing crash dumps. The work we found for grouping crash dumps is mostly based on the similarity of call stacks. The motivation is to match a given failure in the problem database\cite{brodie:automated, 4401026, brodie:quickly,Lohman:2005:QFK:1078027.1078461}.

Bartz et al. \cite{Bartz_findingsimilar} applied a machine learning similarity metric for grouping Windows failure reports. This is done using information from clients when the users describe the symptoms of failures. The primary mechanism for measurements is an adaptation of the Levenshtein edit distance process, which is deemed to be one of the less costly string matching algorithms \cite{Bard:2007:STO:1274531.1274545}. 

Lohman et al. \cite{Lohman:2005:QFK:1078027.1078461} developed the techniques of normalizing strings based on length before comparing them. They applied metrics commonly used in string matching algorithms, including {\it edit distance}, {\it longest common subsequence} and {\it prefix match}. 

Brodie et al. \cite{brodie:automated, brodie:quickly} proposed that similar bugs are likely to produce stacks which resemble one another. To determine if a new failure is originated from the same cause documented in the database, they developed the metrics of Brodie weight for determining similarities between call stacks. The idea is that when measuring similarity, a higher weight is placed upon items that match between the top of two stacks. The assumption is that the closer to the top of a stack a function call is, the more relevant it is to the matching process \cite{brodie:quickly}. 

Besides the above work in grouping crash dumps using call stack similarity, Kim et al.\cite{Kim:2011:2} developed crash graphs to aggregate a set of crash dumps into a graph, which demonstrated to be able to more efficiently identify duplicate bug reports and predict if a given crash will be fixed.

We also find related work which aims to prioritize and reproduce crash dumps. Kim et al. \cite{Kim:2011} proposed that we should focus on diagnosing top crashes, as the observations on Firefox and Thunderbird show that 10 to 20 top crashes account for above 50 \% of total crash reports. They develop a machine learning technique to predict the top crashes in new releases based on the features of top crashes in the past releases.

Artzi et al. \cite{Artzi:2008} developed techniques for creating unit tests for reproducing crash dumps. The approach consists of monitoring phase and test generation phase. The monitoring phase stored copies of the receiver and arguments for each method and the test generation phase restores the method and arguments.

The work on crash dumps also includes empirical studies. Dhaliwal et al.\cite{6080800} found that it takes longer to fix bugs when the group contains crashes caused by multiple bugs. Schroter \cite{5463280} et al. concluded that stack traces in the bug reports indeed help developers fix bugs. 


