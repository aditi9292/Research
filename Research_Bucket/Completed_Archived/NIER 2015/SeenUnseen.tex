\section{Tactic's Implementation: Seen and Unseen}
Our study involved review the source code of over 50 complex, performance centric open source systems including projects such as Google Chromium, Apache Hadoop, and Camel projects. For each of the studied projects we identified architecturally significant requirements, architectural tactics used to address them and source files used to implement tactics.
As a result of this study we observed five issues that significantly influence development of any practical architecture recommender system. Each of these is discussed below:


\noindent \textbf{$\bullet$ No Single Solution.}
There is no single way to address a quality requirements and also no single way to implement an architectural tactic. From one system to another system a tactic can be implemented entirely differently, this divergence is due to the differences in the context and constraints of each projects.
For example, we reviewed the implementation of \emph{heartbeat} tactic for reliability concerns in 25 different software systems. We observed the heartbeat tactic being implemented using (i) direct communication between the emitter and receiver roles found in~\emph{(Chat3 and Smartfrog systems)}, (ii) the observer pattern in which the receiver is registered as a listener to the emitter found in the \emph{Amalgam system}, (iii) the decorator pattern in which the heartbeat functionality was added as a wrapper to a core service found in~\emph{(Rossume} and~\emph{jworkosgi systems)}, and finally (iv) numerous proprietary implementations which did not follow any documented design notion.
Therefore a recommender system can not primarily rely on structural dependencies as a means of learning the best tactic implementation.

\noindent \textbf{$\bullet$ Structure Is Not a Key, But Impacts Quality.}
Unlike design patterns, which tend to be described in terms of classes and their associations , tactics are described in terms of roles and interactions \cite{bass:arch12}.  This means a tactic is not dependent upon a specific {\em structural} format. While a single tactic might be implemented using a variety of design notions or proprietary designs, the structural properties of tactical files can have significant on the quality of the tactic. Flaws such as cyclic dependencies, improper inheritance, unstable interfaces, and modularity violations are strongly correlated to increased bug rates and increased costs of maintaining the software. For example we found several security bug reports on Stack Overflow website where developers misuses \emph{inheritance} relationship in implementation of \emph{sandbox} tactic. In those cases a process outside sandbox had inheritance relationship with a process inside sandbox resulting in a breach into secure zones of the project.
A recommender solution should take into account the internal quality of recommended code to avoid suggesting codes with design and structural flaws.

\noindent \textbf{$\bullet$ Tactical Clones: Right Level of Granularity.}
While the implementation of tactics are different from one system to another system, the intrinsic characteristics of tactics are maintained across different projects. We call these as \emph{architectural or tactical clones}. Based on our observation, tactical clones are the right level of granularity for recommending tactic implementations.
In our code review process, we found that even for a simple tactic like heartbeat the implementation would result in a large number of interrelated files, each playing different roles such as heartbeat emitter, heartbeat receiver, configuration files to set heartbeat intervals and other parameters, supporting classes and interfaces to implement each  tactical roles. More complex tactics, specially the cross-cutting ones can easily impact hundreds of source files. Therefore recommending code snippets for those tactics would create a large search space for the developers with lesser degree of reusability. The lack of structure, and a concrete micro-level design which can be recovered across multiple projects indicates that method level clones are the right level of granularity.  In the next section of this paper we provide examples of such tactical clones.

\noindent \textbf{$\bullet$ Tactics Are Misused, Degraded or Implemented Incorrectly.} Open source repositories contain several cases where architectural tactics have been adopted by the developers without fully understanding the driving forces and variability points \cite{FSE2012} associated with each tactic and consequences of implementing the tactic. The Heartbleed issue is a good example of such misuse. Heartbeat functionality in OpenSSL is an optional feature, while many developers could have easily disabled it in configuration files they fully ignored that. Furthermore, the implementation of heartbeat functionality did not followed solid software engineering practices.

In our analysis of bug reports in tactical fragments of the Hadoop project, we found that if a tactical file had a bug, then 89\% of these issues were due to issues such as unhandled exceptions, type mismatches, or missing values in a configuration file. 
11\% of reports where due to wrong implementation. These bugs involved misconceptions in the use of the tactic, so that the tactic failed to adequately accomplish its architectural task.  These kinds of bugs caused the system to crash under certain circumstances. For example, in one case a replication decision with a complex synchronization mechanism was misunderstood for different types of replica failure. Another example was a scheduling tactic which resulted in deadlock problem. This investigation shows that systems are exposed to new risks during implementation of the tactical decisions. A good tactic recommendation needs to take into account tactical code qualities, the context in which the tactics are adopted and the historical bug fixes and refactoring activities on candidate clone for recommendation. Our recommender system uses a set of static analysis tool to rank recommended tactical code clones based on their quality.

\noindent \textbf{$\bullet$ Object Oriented Metrics Are Not Indicator of Tactical Code Quality.}
Our initial analysis of Chidamber and Kemerer's OO metrics~\cite{491650} and tactical code snippets in Apache Hadoop and OfBiz systems indicates that tactical code snippets tend to relatively a have higher code complexity compared to non-tactical code snippets. For example implementing thread pooling requires devising solutions for thread safe problem which will results in a more complex implementation. Therefore OO metrics such as \emph{WMC (Weighted Methods per Class)} or~\emph{CBO (Coupling Between Object classes)} can not solely be a good indicator of an improved tactical code snippet. A good tactic recommender system must take into account novel code metrics to filter potentially complex code samples which are difficult to comprehend and modify.
